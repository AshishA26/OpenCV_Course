{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpsons Face Recognition Program\n",
    "- Uses tensorflow and Keras 3\n",
    "- Uses GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import caer\n",
    "import canaro\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model expects all image data to be of the same size\n",
    "# i.e. we will have to resize all images in dataset to a particular size\n",
    "IMG_SIZE = (80,80)\n",
    "channels = 1 # i.e. grayscale\n",
    "character_path = r'./simpsons_data/simpsons_dataset/' # path to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a character dictionary, sorting it in descending order\n",
    "\n",
    "# We want to get top 10 characters with most images for that class\n",
    "# - go through every folder, get name of folder and number of images\n",
    "#   in the folder, and store this info in a dictionary (hashmap)\n",
    "character_dict = {}\n",
    "for character in os.listdir(character_path):\n",
    "    character_dict[character] = len(os.listdir(os.path.join(character_path, character)))\n",
    "\n",
    "# sort in decending order\n",
    "character_dict = caer.sort_dict(character_dict, descending=True)\n",
    "\n",
    "character_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the top 10 people with most images\n",
    "characters = []\n",
    "count = 0\n",
    "for i in character_dict:\n",
    "    characters.append(i[0])\n",
    "    count +=1\n",
    "    if count >= 10:\n",
    "        break\n",
    "\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data\n",
    "# - go through every folder inside character_path, and look at every element\n",
    "#   inside the characters list\n",
    "# - it will the images from the top 10 people, to the training set\n",
    "# - a training set is a list. Each element in the list was another list\n",
    "#   of image array and its label\n",
    "train = caer.preprocess_from_dir(character_path, characters, channels=channels, IMG_SIZE=IMG_SIZE, isShuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train) # number of images (training samples) in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data (OpenCV doesn't display well in Jupyter notebooks)\n",
    "\n",
    "# diplay an image in the training set\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(train[0][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate training set into labels and features (separate lists)\n",
    "# and also reshape the featureSet into a 4D tensor, so that it can be \n",
    "# fed into the model without any restrictions\n",
    "featureSet, labels = caer.sep_train(train, IMG_SIZE=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.keras.utils.np_utils import to_categorical # NOTE: Needed utils.np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Normalize the featureSet ==> make data within range of (0,1)\n",
    "featureSet = caer.normalize(featureSet)\n",
    "\n",
    "# convert numerical labels from class vector (integers) to binary class matrix.\n",
    "labels = to_categorical(labels, len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting featureset and labels into training set and validation set\n",
    "# so in this case, 20% goes to validation, 80% goes to training\n",
    "x_train, x_val, y_train, y_val = caer.train_val_split(featureSet, labels, val_ratio=.2)\n",
    "\n",
    "\n",
    "# Extra stuff:\n",
    "# import sklearn.model_selection as skm\n",
    "# split_data = skm.train_test_split(featureSet, labels, test_size=.2)\n",
    "# x_train, x_val, y_train, y_val = (np.array(item) for item in split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can now delete unneeded variables\n",
    "del train \n",
    "del featureSet\n",
    "del labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful variables when training\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data generator\n",
    "# - image generator that makes new images from existing ones to improve our network\n",
    "# - introduces randomness in network ==> better accuracy\n",
    "datagen = canaro.generators.imageDataGenerator()\n",
    "train_gen = datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old code from video, does not work:\n",
    "# model = canaro.models.createSimpsonsModel(IMG_SIZE=IMG_SIZE, channels=channels, \n",
    "#                                           output_dim=len(characters), loss='binary_crossentropy', decay=1e-6, learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Works:\n",
    "# Create our model (returns a compiled model)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "\n",
    "output_dim=10\n",
    "\n",
    "w, h = IMG_SIZE[:2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(w, h,channels)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu')) \n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "# from keras.models import Sequential, Model\n",
    "# from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Input, Reshape, Concatenate, GlobalAveragePooling2D, BatchNormalization, Dropout, Activation, GlobalMaxPooling2D\n",
    "# from keras.utils import Sequence\n",
    "# import tensorflow\n",
    "# # Create our model (returns a compiled model)\n",
    "# def create_ST_layer(input_shape = (64, 128, 3)):\n",
    "#     input_img = Input(shape=input_shape)\n",
    "#     model = Conv2D(48, kernel_size=(5, 5), input_shape = input_shape, strides = (1, 1), activation = 'relu')(input_img)\n",
    "#     model = MaxPooling2D(pool_size=(2, 2), strides = (2, 2))(model)\n",
    "#     model = Conv2D(32, kernel_size=(5, 5), strides = (1, 1), activation = 'relu')(model)\n",
    "#     model = MaxPooling2D(pool_size=(2, 2), strides = (2, 2))(model)\n",
    "#     model = Dense(50, activation = 'relu')(model)\n",
    "#     model = Dense(6)(model)\n",
    "#     model = tensorflow.keras.Model(inputs=input_img, outputs= model)\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_ST_layer()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.compile(loss='binary_crossentropy')\n",
    "# create a callbacks list\n",
    "# contains a learning rate scheduler - schedules learning rate at certain intervals to allow the network to train better\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "callbacks_list = [LearningRateScheduler(canaro.lr_schedule)]\n",
    "\n",
    "training = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(x_train)//BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    validation_steps=len(y_val)//BATCH_SIZE,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'./simpsons_data/simpsons_dataset/charles_montgomery_burns/pic_0011.jpg'\n",
    "\n",
    "img = cv.imread(test_path)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(image):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    image = cv.resize(image, IMG_SIZE)\n",
    "    image = caer.reshape(image, IMG_SIZE, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(prepare(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting class with the highest probability\n",
    "print(characters[np.argmax(predictions[0])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
